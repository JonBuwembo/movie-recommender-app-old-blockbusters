{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b64cf8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  3606 movies with overviews\n",
      "   movie_id                        title  \\\n",
      "0         1                    Toy Story   \n",
      "1         2                      Jumanji   \n",
      "2         3             Grumpier Old Men   \n",
      "3         4            Waiting to Exhale   \n",
      "4         5  Father of the Bride Part II   \n",
      "\n",
      "                                            overview  \\\n",
      "0  Led by Woody, Andy's toys live happily in his ...   \n",
      "1  When siblings Judy and Peter discover an encha...   \n",
      "2  A family wedding reignites the ancient feud be...   \n",
      "3  Cheated on, mistreated and stepped on, the wom...   \n",
      "4  Just when George Banks has recovered from his ...   \n",
      "\n",
      "                          genre  \n",
      "0   Animation Children's Comedy  \n",
      "1  Adventure Children's Fantasy  \n",
      "2                Comedy Romance  \n",
      "3                  Comedy Drama  \n",
      "4                        Comedy  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../../backend/database\") \n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from db_connection import get_db_connection\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv_path = Path(\".env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "conn = get_db_connection()\n",
    "\n",
    "# Read variables\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\") \n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "engine = create_engine(f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "if conn is None:\n",
    "    raise Exception(\"Failed to connect to database.\")\n",
    "\n",
    "# query only movies that have an overview (some don't)\n",
    "# include genres and moviegenres table\n",
    "# show genres aggregated as one string, spaced per genre.\n",
    "query = \"\"\"\n",
    "SELECT m.movie_id AS movie_id, m.title, m.overview, STRING_AGG(g.name, ' ') AS genre\n",
    "FROM movies m \n",
    "JOIN \"MovieGenres\" gm ON m.movie_id = gm.movie_id\n",
    "JOIN genres g ON gm.genre_id = g.genre_id\n",
    "WHERE m.overview IS NOT NULL \n",
    "AND TRIM(m.overview) != ''\n",
    "GROUP BY m.movie_id, m.title, m.overview\n",
    " \"\"\"\n",
    "\n",
    "movies_df = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"Loaded  {len(movies_df)} movies with overviews\")\n",
    "print(movies_df.head())\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for:  Toy Story\n",
      "                      title\n",
      "2831            Toy Story 2\n",
      "1017  Rebel Without a Cause\n",
      "1837              Condorman\n",
      "2887        Man on the Moon\n",
      "455                  Malice\n",
      "418       For Love or Money\n",
      "3063        Bound for Glory\n",
      "1792           Child's Play\n",
      "1793         Child's Play 2\n",
      "1794         Child's Play 3\n"
     ]
    }
   ],
   "source": [
    "def compute_tfidf(corpus, stop_words='english'):\n",
    "    # Corpus is all text documents \"movie overviews and genres\"\n",
    "    # returns: tfidf_matrix, vectorizer\n",
    "\n",
    "    # ignore common english words \"the\", \"and\", \"of\"\n",
    "    # Vectorizer is a trained TfidfVectorizer object for inspecting feature names or transforming text.\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    # Sparse matrix: Each row is a movie, each column is a word from the its vocabulary, each entry is the TF_IDF score of that word in that movie.\n",
    "    # Transformation: converts each document into a vector of TF-IDF values. \n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    return tfidf_matrix, vectorizer\n",
    "\n",
    "def get_top_n_recommendations(tfidf_matrix, movie_index, movies_df, n=10):\n",
    "    # movie index --> first movie. \n",
    "    # tfidf_matrix --> the TF-IDF vectors for all movies\n",
    "    # movies_df --> dataframe of agreggated data queried from database\n",
    "    # n=10 (can change), number of top recommendations to return.\n",
    "\n",
    "    # Computes pairwise cosine similarity between all movie vectors.\n",
    "    # measures how similar two vectors are based on their direction, ignoring magnitude.\n",
    "    # cosine_sim a square matrix of shape: (num_movies, num_movies)\n",
    "    # 0 means no similarity, 1 means identical.\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    # 1-d flattened array of similarity scores between passed in movie and all other movies.\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_index]))\n",
    "    # a list of tuples sorted descending order.movie_index [(0, 1.0), (1, 0.55), (2, 0.43), ...]\n",
    "    # shape: (movie_index, similarity) \n",
    "    # x[1] sorts by similarity value not movie index.\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Get list of row indices in dataframe with top N similar movies.\n",
    "    # i for movie_index, similarity in all sim scores starting from the second most similar to the nth.\n",
    "    # first one is the 0 index, which is our movie we passed in, so we skip.\n",
    "    top_indices = [i for i, _ in sim_scores[1:n+1]]\n",
    "    # get rows in df with corresponding to top movies.\n",
    "    # top movies have all three metadata sql queried earlier.\n",
    "    return movies_df.iloc[top_indices]\n",
    "\n",
    "# TF-IDF is case sensitive\n",
    "movies_df['clean_overview'] = movies_df['overview'].str.lower()\n",
    "\n",
    "\n",
    "tfidf_matrix, vectorizer = compute_tfidf(movies_df['clean_overview'].tolist())\n",
    "recommendations = get_top_n_recommendations(tfidf_matrix, movie_index=0, movies_df=movies_df)\n",
    "\n",
    "query_movie = movies_df.iloc[0] # get the first movie\n",
    "\n",
    "print('Recommendations for: ', query_movie[\"title\"])\n",
    "print(recommendations[['title']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "202f4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"C:/Users/jonab/.vscode/PROJECTS/Web Development Projects/Movie Recommendation Application/backend/artifacts/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(\"C:/Users/jonab/.vscode/PROJECTS/Web Development Projects/Movie Recommendation Application/backend/artifacts/tfidf_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MovieRecommender Virtual Env Kernel",
   "language": "python",
   "name": "movie_reco_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
